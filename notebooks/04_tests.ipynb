{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"retail_p1\"\n",
    "NAMESPACE = f\"{CATALOG}.{SCHEMA}\"\n",
    "\n",
    "BRONZE_ORDERS_TABLE = f\"{NAMESPACE}.bronze_orders\"\n",
    "SILVER_ORDERS_TABLE = f\"{NAMESPACE}.silver_orders_clean\"\n",
    "SILVER_CUSTOMERS_SCD2_TABLE = f\"{NAMESPACE}.silver_customers_scd2\"\n",
    "SILVER_PRODUCTS_LATEST_TABLE = f\"{NAMESPACE}.silver_products_latest\"\n",
    "GOLD_DAILY_REVENUE_TABLE = f\"{NAMESPACE}.gold_daily_revenue\"\n",
    "DQ_RESULTS_TABLE = f\"{NAMESPACE}.dq_results\"\n",
    "\n",
    "\n",
    "def get_widget(name: str, default: str) -> str:\n",
    "    try:\n",
    "        dbutils.widgets.text(name, default)\n",
    "        value = dbutils.widgets.get(name).strip()\n",
    "        return value or default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "FRESHNESS_HOURS = int(get_widget(\"freshness_hours\", \"168\"))\n",
    "FAIL_ON_ERROR = get_widget(\"fail_on_error\", \"false\").lower() == \"true\"\n",
    "RUN_ID = get_widget(\"run_id\", datetime.now(timezone.utc).strftime(\"%Y%m%d%H%M%S\"))\n",
    "RUN_TS = datetime.now(timezone.utc)\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {NAMESPACE}\")\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {DQ_RESULTS_TABLE} (\n",
    "      check_name STRING,\n",
    "      check_type STRING,\n",
    "      status STRING,\n",
    "      failed_count DOUBLE,\n",
    "      threshold DOUBLE,\n",
    "      run_ts TIMESTAMP,\n",
    "      details STRING\n",
    "    ) USING DELTA\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def run_check(check_name: str, check_type: str, failed_count_sql: str, threshold: float = 0.0, details: str = \"\"):\n",
    "    failed_raw = spark.sql(failed_count_sql).first()[0]\n",
    "    failed_count = float(failed_raw) if failed_raw is not None else 0.0\n",
    "    status = \"PASS\" if failed_count <= threshold else \"FAIL\"\n",
    "\n",
    "    result_df = spark.createDataFrame(\n",
    "        [\n",
    "            (\n",
    "                check_name,\n",
    "                check_type,\n",
    "                status,\n",
    "                failed_count,\n",
    "                float(threshold),\n",
    "                RUN_TS,\n",
    "                f\"run_id={RUN_ID}; {details}\",\n",
    "            )\n",
    "        ],\n",
    "        \"check_name string, check_type string, status string, failed_count double, threshold double, run_ts timestamp, details string\",\n",
    "    )\n",
    "    result_df.write.format(\"delta\").mode(\"append\").saveAsTable(DQ_RESULTS_TABLE)\n",
    "    print(f\"[{status}] {check_name}: failed_count={failed_count}, threshold={threshold}\")\n",
    "    return status, failed_count\n",
    "\n",
    "\n",
    "check_definitions = [\n",
    "    (\n",
    "        \"silver_orders_unique_key\",\n",
    "        \"uniqueness\",\n",
    "        f\"\"\"\n",
    "        SELECT COUNT(*) AS failed_count\n",
    "        FROM (\n",
    "          SELECT order_id, product_id\n",
    "          FROM {SILVER_ORDERS_TABLE}\n",
    "          GROUP BY order_id, product_id\n",
    "          HAVING COUNT(*) > 1\n",
    "        )\n",
    "        \"\"\",\n",
    "        0.0,\n",
    "        \"Expect one row per (order_id, product_id) in silver_orders_clean.\",\n",
    "    ),\n",
    "    (\n",
    "        \"silver_orders_null_customer_id\",\n",
    "        \"null_check\",\n",
    "        f\"SELECT COUNT(*) AS failed_count FROM {SILVER_ORDERS_TABLE} WHERE customer_id IS NULL\",\n",
    "        0.0,\n",
    "        \"Customer id is required in silver_orders_clean.\",\n",
    "    ),\n",
    "    (\n",
    "        \"silver_orders_quantity_positive\",\n",
    "        \"domain_check\",\n",
    "        f\"SELECT COUNT(*) AS failed_count FROM {SILVER_ORDERS_TABLE} WHERE quantity <= 0 OR quantity IS NULL\",\n",
    "        0.0,\n",
    "        \"Quantity must be positive.\",\n",
    "    ),\n",
    "    (\n",
    "        \"silver_orders_price_non_negative\",\n",
    "        \"domain_check\",\n",
    "        f\"SELECT COUNT(*) AS failed_count FROM {SILVER_ORDERS_TABLE} WHERE price < 0 OR price IS NULL\",\n",
    "        0.0,\n",
    "        \"Price must be non-negative.\",\n",
    "    ),\n",
    "    (\n",
    "        \"silver_orders_orphan_customers\",\n",
    "        \"referential_integrity\",\n",
    "        f\"\"\"\n",
    "        SELECT COUNT(*) AS failed_count\n",
    "        FROM {SILVER_ORDERS_TABLE} o\n",
    "        LEFT JOIN {SILVER_CUSTOMERS_SCD2_TABLE} c\n",
    "          ON o.customer_id = c.customer_id\n",
    "          AND c.is_current = true\n",
    "        WHERE c.customer_id IS NULL\n",
    "        \"\"\",\n",
    "        0.0,\n",
    "        \"All orders must map to a current customer row.\",\n",
    "    ),\n",
    "    (\n",
    "        \"silver_orders_orphan_products\",\n",
    "        \"referential_integrity\",\n",
    "        f\"\"\"\n",
    "        SELECT COUNT(*) AS failed_count\n",
    "        FROM {SILVER_ORDERS_TABLE} o\n",
    "        LEFT JOIN {SILVER_PRODUCTS_LATEST_TABLE} p\n",
    "          ON o.product_id = p.product_id\n",
    "        WHERE p.product_id IS NULL\n",
    "        \"\"\",\n",
    "        0.0,\n",
    "        \"All orders must map to product dimension rows.\",\n",
    "    ),\n",
    "    (\n",
    "        \"scd2_single_current_row\",\n",
    "        \"scd2_integrity\",\n",
    "        f\"\"\"\n",
    "        SELECT COUNT(*) AS failed_count\n",
    "        FROM (\n",
    "          SELECT customer_id\n",
    "          FROM {SILVER_CUSTOMERS_SCD2_TABLE}\n",
    "          GROUP BY customer_id\n",
    "          HAVING SUM(CASE WHEN is_current THEN 1 ELSE 0 END) <> 1\n",
    "        )\n",
    "        \"\"\",\n",
    "        0.0,\n",
    "        \"Each customer must have exactly one current SCD2 row.\",\n",
    "    ),\n",
    "    (\n",
    "        \"scd2_no_overlapping_windows\",\n",
    "        \"scd2_integrity\",\n",
    "        f\"\"\"\n",
    "        SELECT COUNT(DISTINCT customer_id) AS failed_count\n",
    "        FROM (\n",
    "          SELECT a.customer_id\n",
    "          FROM {SILVER_CUSTOMERS_SCD2_TABLE} a\n",
    "          JOIN {SILVER_CUSTOMERS_SCD2_TABLE} b\n",
    "           ON a.customer_id = b.customer_id\n",
    "           AND (\n",
    "             a.valid_from < b.valid_from\n",
    "             OR (a.valid_from = b.valid_from AND a.customer_sk < b.customer_sk)\n",
    "           )\n",
    "           AND coalesce(a.valid_to, CAST('9999-12-31 00:00:00' AS TIMESTAMP)) > b.valid_from\n",
    "           AND coalesce(b.valid_to, CAST('9999-12-31 00:00:00' AS TIMESTAMP)) > a.valid_from\n",
    "        )\n",
    "        \"\"\",\n",
    "        0.0,\n",
    "        \"SCD2 validity windows must not overlap for the same customer.\",\n",
    "    ),\n",
    "    (\n",
    "        \"gold_daily_revenue_non_negative_metrics\",\n",
    "        \"gold_sanity\",\n",
    "        f\"\"\"\n",
    "        SELECT COUNT(*) AS failed_count\n",
    "        FROM {GOLD_DAILY_REVENUE_TABLE}\n",
    "        WHERE gross_revenue < 0 OR net_revenue < 0 OR aov < 0 OR order_count < 0\n",
    "        \"\"\",\n",
    "        0.0,\n",
    "        \"Gold revenue metrics should not be negative.\",\n",
    "    ),\n",
    "    (\n",
    "        \"bronze_orders_freshness\",\n",
    "        \"freshness\",\n",
    "        f\"\"\"\n",
    "        SELECT\n",
    "          CASE\n",
    "            WHEN MAX(_ingest_ts) IS NULL THEN 1\n",
    "            WHEN ((unix_timestamp(current_timestamp()) - unix_timestamp(MAX(_ingest_ts))) / 3600.0) > {FRESHNESS_HOURS}\n",
    "              THEN 1\n",
    "            ELSE 0\n",
    "          END AS failed_count\n",
    "        FROM {BRONZE_ORDERS_TABLE}\n",
    "        \"\"\",\n",
    "        0.0,\n",
    "        f\"Bronze orders should be newer than {FRESHNESS_HOURS} hours.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "results = [run_check(*check_def) for check_def in check_definitions]\n",
    "failures = [row for row in results if row[0] == \"FAIL\"]\n",
    "\n",
    "summary_df = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT\n",
    "      run_ts,\n",
    "      SUM(CASE WHEN status = 'PASS' THEN 1 ELSE 0 END) AS pass_count,\n",
    "      SUM(CASE WHEN status = 'FAIL' THEN 1 ELSE 0 END) AS fail_count\n",
    "    FROM {DQ_RESULTS_TABLE}\n",
    "    WHERE details LIKE 'run_id={RUN_ID};%'\n",
    "    GROUP BY run_ts\n",
    "    ORDER BY run_ts DESC\n",
    "    \"\"\"\n",
    ")\n",
    "summary_df.show(truncate=False)\n",
    "\n",
    "if FAIL_ON_ERROR and failures:\n",
    "    raise RuntimeError(f\"Data quality checks failed for run_id={RUN_ID}: {failures}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
