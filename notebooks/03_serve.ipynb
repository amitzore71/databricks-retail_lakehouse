{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"retail_p1\"\n",
    "NAMESPACE = f\"{CATALOG}.{SCHEMA}\"\n",
    "\n",
    "SILVER_ORDERS_TABLE = f\"{NAMESPACE}.silver_orders_clean\"\n",
    "SILVER_PRODUCTS_LATEST_TABLE = f\"{NAMESPACE}.silver_products_latest\"\n",
    "\n",
    "GOLD_DAILY_REVENUE_TABLE = f\"{NAMESPACE}.gold_daily_revenue\"\n",
    "GOLD_CUSTOMER_LTV_TABLE = f\"{NAMESPACE}.gold_customer_ltv\"\n",
    "GOLD_CATEGORY_PERFORMANCE_TABLE = f\"{NAMESPACE}.gold_category_performance\"\n",
    "\n",
    "CANCELED_STATUSES = [\n",
    "    \"canceled\",\n",
    "    \"cancelled\",\n",
    "    \"unavailable\",\n",
    "]\n",
    "RETURNED_STATUSES = [\n",
    "    \"returned\",\n",
    "    \"return_requested\",\n",
    "]\n",
    "CANCELED_OR_RETURNED_STATUSES = CANCELED_STATUSES + RETURNED_STATUSES\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {NAMESPACE}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = (\n",
    "    spark.table(SILVER_ORDERS_TABLE)\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        \"customer_id\",\n",
    "        \"product_id\",\n",
    "        F.to_timestamp(\"order_ts\").alias(\"order_ts\"),\n",
    "        F.col(\"quantity\").cast(\"int\").alias(\"quantity\"),\n",
    "        F.col(\"price\").cast(\"double\").alias(\"price\"),\n",
    "        F.lower(F.col(\"status\")).alias(\"status\"),\n",
    "        F.col(\"channel\").cast(\"string\").alias(\"channel\"),\n",
    "    )\n",
    "    .withColumn(\"dt\", F.to_date(\"order_ts\"))\n",
    "    .withColumn(\"line_revenue\", F.col(\"quantity\") * F.col(\"price\"))\n",
    "    .withColumn(\n",
    "        \"net_line_revenue\",\n",
    "        F.when(\n",
    "            F.col(\"status\").isin(*CANCELED_OR_RETURNED_STATUSES),\n",
    "            F.lit(0.0),\n",
    "        ).otherwise(F.col(\"line_revenue\")),\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_daily_revenue = (\n",
    "    orders.groupBy(\"dt\")\n",
    "    .agg(\n",
    "        F.round(F.sum(\"line_revenue\"), 2).alias(\"gross_revenue\"),\n",
    "        F.round(F.sum(\"net_line_revenue\"), 2).alias(\"net_revenue\"),\n",
    "        F.countDistinct(\"order_id\").alias(\"order_count\"),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"aov\",\n",
    "        F.round(\n",
    "            F.when(F.col(\"order_count\") > 0, F.col(\"net_revenue\") / F.col(\"order_count\")).otherwise(0.0),\n",
    "            2,\n",
    "        ),\n",
    "    )\n",
    "    .select(\"dt\", \"gross_revenue\", \"net_revenue\", \"order_count\", \"aov\")\n",
    ")\n",
    "\n",
    "(\n",
    "    gold_daily_revenue.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(GOLD_DAILY_REVENUE_TABLE)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order_ts = orders.agg(F.max(\"order_ts\").alias(\"max_order_ts\")).first()[\"max_order_ts\"]\n",
    "\n",
    "if max_order_ts is None:\n",
    "    gold_customer_ltv = spark.createDataFrame(\n",
    "        [],\n",
    "        \"customer_id string, ltv_90d double, ltv_180d double, ltv_total double\",\n",
    "    )\n",
    "else:\n",
    "    ltv_cutoff_90d = max_order_ts - timedelta(days=90)\n",
    "    ltv_cutoff_180d = max_order_ts - timedelta(days=180)\n",
    "    gold_customer_ltv = (\n",
    "        orders.filter(F.col(\"customer_id\").isNotNull())\n",
    "        .groupBy(\"customer_id\")\n",
    "        .agg(\n",
    "            F.round(\n",
    "                F.sum(\n",
    "                    F.when(\n",
    "                        F.col(\"order_ts\") >= F.lit(ltv_cutoff_90d),\n",
    "                        F.col(\"net_line_revenue\"),\n",
    "                    ).otherwise(0.0)\n",
    "                ),\n",
    "                2,\n",
    "            ).alias(\"ltv_90d\"),\n",
    "            F.round(\n",
    "                F.sum(\n",
    "                    F.when(\n",
    "                        F.col(\"order_ts\") >= F.lit(ltv_cutoff_180d),\n",
    "                        F.col(\"net_line_revenue\"),\n",
    "                    ).otherwise(0.0)\n",
    "                ),\n",
    "                2,\n",
    "            ).alias(\"ltv_180d\"),\n",
    "            F.round(F.sum(\"net_line_revenue\"), 2).alias(\"ltv_total\"),\n",
    "        )\n",
    "        .select(\"customer_id\", \"ltv_90d\", \"ltv_180d\", \"ltv_total\")\n",
    "    )\n",
    "\n",
    "(\n",
    "    gold_customer_ltv.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(GOLD_CUSTOMER_LTV_TABLE)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = spark.table(SILVER_PRODUCTS_LATEST_TABLE).select(\n",
    "    \"product_id\",\n",
    "    F.coalesce(F.col(\"category\"), F.lit(\"unknown\")).alias(\"category\"),\n",
    ")\n",
    "\n",
    "orders_with_category = orders.join(products, on=\"product_id\", how=\"left\").withColumn(\n",
    "    \"category\",\n",
    "    F.coalesce(F.col(\"category\"), F.lit(\"unknown\")),\n",
    ")\n",
    "\n",
    "gold_category_performance = (\n",
    "    orders_with_category.groupBy(\"dt\", \"category\")\n",
    "    .agg(\n",
    "        F.round(F.sum(\"net_line_revenue\"), 2).alias(\"revenue\"),\n",
    "        F.sum(\"quantity\").alias(\"units_sold\"),\n",
    "        F.countDistinct(\"order_id\").alias(\"total_orders\"),\n",
    "        F.countDistinct(\n",
    "            F.when(\n",
    "                F.col(\"status\").isin(*RETURNED_STATUSES),\n",
    "                F.col(\"order_id\"),\n",
    "            )\n",
    "        ).alias(\"returned_orders\"),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"return_rate\",\n",
    "        F.round(\n",
    "            F.when(F.col(\"total_orders\") > 0, F.col(\"returned_orders\") / F.col(\"total_orders\")).otherwise(0.0),\n",
    "            4,\n",
    "        ),\n",
    "    )\n",
    "    .select(\"dt\", \"category\", \"revenue\", \"units_sold\", \"return_rate\")\n",
    ")\n",
    "\n",
    "(\n",
    "    gold_category_performance.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .saveAsTable(GOLD_CATEGORY_PERFORMANCE_TABLE)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_sql = [\n",
    "    f\"OPTIMIZE {SILVER_ORDERS_TABLE} ZORDER BY (order_ts, customer_id)\",\n",
    "    f\"OPTIMIZE {GOLD_DAILY_REVENUE_TABLE} ZORDER BY (dt)\",\n",
    "    f\"OPTIMIZE {GOLD_CUSTOMER_LTV_TABLE} ZORDER BY (customer_id)\",\n",
    "    f\"OPTIMIZE {GOLD_CATEGORY_PERFORMANCE_TABLE} ZORDER BY (dt, category)\",\n",
    "    f\"ANALYZE TABLE {GOLD_DAILY_REVENUE_TABLE} COMPUTE STATISTICS\",\n",
    "    f\"ANALYZE TABLE {GOLD_CUSTOMER_LTV_TABLE} COMPUTE STATISTICS\",\n",
    "    f\"ANALYZE TABLE {GOLD_CATEGORY_PERFORMANCE_TABLE} COMPUTE STATISTICS\",\n",
    "]\n",
    "\n",
    "for statement in optimization_sql:\n",
    "    try:\n",
    "        spark.sql(statement)\n",
    "        print(f\"[OK] {statement}\")\n",
    "    except Exception as exc:\n",
    "        print(f\"[WARN] {statement} failed: {exc}\")\n",
    "\n",
    "print(\"[DONE] Gold marts refreshed and optimization commands executed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
