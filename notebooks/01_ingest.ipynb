{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "CATALOG = \"main\"\n",
    "SCHEMA = \"retail_p1\"\n",
    "NAMESPACE = f\"{CATALOG}.{SCHEMA}\"\n",
    "RAW_BASE_PATH = f\"/Volumes/{CATALOG}/{SCHEMA}/raw\"\n",
    "\n",
    "BRONZE_ORDERS_TABLE = f\"{NAMESPACE}.bronze_orders\"\n",
    "BRONZE_CUSTOMERS_TABLE = f\"{NAMESPACE}.bronze_customers\"\n",
    "BRONZE_PRODUCTS_TABLE = f\"{NAMESPACE}.bronze_products\"\n",
    "\n",
    "\n",
    "def get_widget(name: str, default: str) -> str:\n",
    "    try:\n",
    "        dbutils.widgets.text(name, default)\n",
    "        value = dbutils.widgets.get(name).strip()\n",
    "        return value or default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "BATCH_ID = get_widget(\"batch_id\", datetime.now(timezone.utc).strftime(\"%Y-%m-%d\"))\n",
    "SOURCE_PREFIX = get_widget(\"source_prefix\", \"olist\")\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {NAMESPACE}\")\n",
    "\n",
    "\n",
    "def read_csv(file_name: str):\n",
    "    path = f\"{RAW_BASE_PATH}/{SOURCE_PREFIX}/{file_name}\"\n",
    "    return (\n",
    "        spark.read.option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .csv(path)\n",
    "    )\n",
    "\n",
    "\n",
    "def table_exists(table_name: str) -> bool:\n",
    "    namespace, object_name = table_name.rsplit(\".\", 1)\n",
    "    return spark.sql(f\"SHOW TABLES IN {namespace} LIKE '{object_name}'\").limit(1).count() > 0\n",
    "\n",
    "\n",
    "def append_without_same_batch(df, table_name: str, key_columns: list[str]) -> None:\n",
    "    # Normalize duplicate keys inside the incoming batch before anti-joining existing rows.\n",
    "    output_df = df.dropDuplicates(key_columns)\n",
    "    if table_exists(table_name):\n",
    "        existing_batch_keys = (\n",
    "            spark.table(table_name)\n",
    "            .filter(F.col(\"_batch_id\") == BATCH_ID)\n",
    "            .select(*key_columns)\n",
    "            .dropDuplicates()\n",
    "        )\n",
    "        output_df = output_df.join(existing_batch_keys, key_columns, \"left_anti\")\n",
    "\n",
    "    row_count = output_df.count()\n",
    "    if row_count == 0:\n",
    "        print(f\"[SKIP] {table_name}: no new rows for batch_id={BATCH_ID}\")\n",
    "        return\n",
    "\n",
    "    (\n",
    "        output_df.write.format(\"delta\")\n",
    "        .mode(\"append\")\n",
    "        .saveAsTable(table_name)\n",
    "    )\n",
    "    print(f\"[WRITE] {table_name}: wrote {row_count} rows for batch_id={BATCH_ID}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read public Olist source files from Unity Catalog Volumes.\n",
    "orders_raw = read_csv(\"olist_orders_dataset.csv\")\n",
    "order_items_raw = read_csv(\"olist_order_items_dataset.csv\")\n",
    "payments_raw = read_csv(\"olist_order_payments_dataset.csv\")\n",
    "customers_raw = read_csv(\"olist_customers_dataset.csv\")\n",
    "products_raw = read_csv(\"olist_products_dataset.csv\")\n",
    "category_translation_raw = read_csv(\"product_category_name_translation.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bronze_orders from order headers, items, and payment type as channel.\n",
    "payments_primary = (\n",
    "    payments_raw.select(\"order_id\", \"payment_type\", \"payment_value\", \"payment_sequential\")\n",
    "    .withColumn(\n",
    "        \"_rn\",\n",
    "        F.row_number().over(\n",
    "            Window.partitionBy(\"order_id\").orderBy(\n",
    "                F.col(\"payment_value\").desc_nulls_last(),\n",
    "                F.col(\"payment_sequential\").desc_nulls_last(),\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    .filter(F.col(\"_rn\") == 1)\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        F.coalesce(F.col(\"payment_type\"), F.lit(\"online\")).alias(\"channel\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "order_lines = (\n",
    "    order_items_raw.select(\n",
    "        \"order_id\",\n",
    "        \"product_id\",\n",
    "        F.col(\"price\").cast(\"double\").alias(\"item_price\"),\n",
    "    )\n",
    "    .withColumn(\"quantity\", F.lit(1))\n",
    ")\n",
    "\n",
    "bronze_orders = (\n",
    "    orders_raw.select(\n",
    "        \"order_id\",\n",
    "        \"customer_id\",\n",
    "        F.col(\"order_purchase_timestamp\").cast(\"timestamp\").alias(\"order_ts\"),\n",
    "        F.col(\"order_status\").alias(\"status\"),\n",
    "    )\n",
    "    .join(order_lines, on=\"order_id\", how=\"inner\")\n",
    "    .join(payments_primary, on=\"order_id\", how=\"left\")\n",
    "    .withColumn(\"channel\", F.coalesce(F.col(\"channel\"), F.lit(\"online\")))\n",
    "    .groupBy(\"order_id\", \"customer_id\", \"product_id\", \"order_ts\", \"status\", \"channel\")\n",
    "    .agg(\n",
    "        F.sum(\"quantity\").cast(\"int\").alias(\"quantity\"),\n",
    "        F.round(F.sum(\"item_price\"), 2).cast(\"double\").alias(\"price\"),\n",
    "    )\n",
    "    .withColumn(\"_batch_id\", F.lit(BATCH_ID))\n",
    "    .withColumn(\"_ingest_ts\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        \"customer_id\",\n",
    "        \"product_id\",\n",
    "        \"order_ts\",\n",
    "        \"quantity\",\n",
    "        \"price\",\n",
    "        \"status\",\n",
    "        \"channel\",\n",
    "        \"_batch_id\",\n",
    "        \"_ingest_ts\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Olist does not include email/country directly, so we normalize to a stable contract.\n",
    "bronze_customers = (\n",
    "    customers_raw.select(\n",
    "        \"customer_id\",\n",
    "        F.concat(F.col(\"customer_unique_id\"), F.lit(\"@unknown.local\")).alias(\"email\"),\n",
    "        F.col(\"customer_city\").alias(\"city\"),\n",
    "        F.lit(\"Brazil\").alias(\"country\"),\n",
    "    )\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "    .withColumn(\"_batch_id\", F.lit(BATCH_ID))\n",
    "    .withColumn(\"_ingest_ts\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"customer_id\",\n",
    "        \"email\",\n",
    "        \"city\",\n",
    "        \"country\",\n",
    "        \"updated_at\",\n",
    "        \"_batch_id\",\n",
    "        \"_ingest_ts\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lookup = category_translation_raw.select(\n",
    "    F.col(\"product_category_name\").alias(\"raw_category\"),\n",
    "    F.col(\"product_category_name_english\").alias(\"category\"),\n",
    ")\n",
    "\n",
    "price_lookup = (\n",
    "    order_items_raw.groupBy(\"product_id\")\n",
    "    .agg(F.round(F.avg(F.col(\"price\").cast(\"double\")), 2).alias(\"list_price\"))\n",
    ")\n",
    "\n",
    "bronze_products = (\n",
    "    products_raw.select(\"product_id\", \"product_category_name\")\n",
    "    .join(\n",
    "        category_lookup,\n",
    "        on=F.col(\"product_category_name\") == F.col(\"raw_category\"),\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .drop(\"raw_category\")\n",
    "    .join(price_lookup, on=\"product_id\", how=\"left\")\n",
    "    .withColumn(\"category\", F.coalesce(F.col(\"category\"), F.col(\"product_category_name\")))\n",
    "    .withColumn(\"brand\", F.lit(\"unknown\"))\n",
    "    .withColumn(\"list_price\", F.coalesce(F.col(\"list_price\"), F.lit(0.0)))\n",
    "    .withColumn(\"updated_at\", F.current_timestamp())\n",
    "    .withColumn(\"_batch_id\", F.lit(BATCH_ID))\n",
    "    .withColumn(\"_ingest_ts\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"product_id\",\n",
    "        \"category\",\n",
    "        \"brand\",\n",
    "        \"list_price\",\n",
    "        \"updated_at\",\n",
    "        \"_batch_id\",\n",
    "        \"_ingest_ts\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_without_same_batch(\n",
    "    bronze_orders,\n",
    "    BRONZE_ORDERS_TABLE,\n",
    "    [\"order_id\", \"product_id\"],\n",
    ")\n",
    "append_without_same_batch(\n",
    "    bronze_customers,\n",
    "    BRONZE_CUSTOMERS_TABLE,\n",
    "    [\"customer_id\"],\n",
    ")\n",
    "append_without_same_batch(\n",
    "    bronze_products,\n",
    "    BRONZE_PRODUCTS_TABLE,\n",
    "    [\"product_id\"],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
